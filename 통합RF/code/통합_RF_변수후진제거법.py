# -*- coding: utf-8 -*-
"""
í†µí•© ëœë¤í¬ë ˆìŠ¤íŠ¸ í•™ìŠµ + ë³€ìˆ˜ ì¤‘ìš”ë„ ê¸°ë°˜ í›„ì§„ì œê±° ì‹¤í—˜
- ì „ì²´ í†µí•© ë°ì´í„°ë¡œ RandomForest í•™ìŠµ
- ë³€ìˆ˜ ì¤‘ìš”ë„ ê³„ì‚° ë° ëˆ„ì  ì¤‘ìš”ë„ ê·¸ë˜í”„
- ì¤‘ìš”ë„ ë‚®ì€ ìˆœì„œëŒ€ë¡œ ë³€ìˆ˜ ì œê±°í•˜ë©° RÂ² / RMSE ë³€í™” ë¶„ì„
"""

import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
import matplotlib.pyplot as plt
import os
import numpy as np

# âœ… macOS í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

# ======================================================
# ğŸ”¹ ê²½ë¡œ ì„¤ì •
# ======================================================
file_path = "/Users/parkhyeji/Desktop/RE_PV/ë°ì´í„°/ì´ìƒì¹˜ì œê±°_í›„/ì¤‘ë¶€+ë™ì„œ.csv"
save_dir = "/Users/parkhyeji/Desktop/RE_PV/RF/data/í†µí•©RF/ì¤‘ë¶€+ë™ì„œ_ë³€ìˆ˜í›„ì§„ì œê±°"
os.makedirs(save_dir, exist_ok=True)

# ğŸ”¹ ì €ì¥ íŒŒì¼
output_csv = os.path.join(save_dir, "ì¤‘ë¶€+ë™ì„œ_RF_í†µí•©ê²°ê³¼.csv")
importance_csv = os.path.join(save_dir, "ì¤‘ë¶€+ë™ì„œ_ë³€ìˆ˜ì¤‘ìš”ë„.csv")
importance_img = os.path.join(save_dir, "ì¤‘ë¶€+ë™ì„œ_ë³€ìˆ˜ì¤‘ìš”ë„.png")
cumulative_img = os.path.join(save_dir, "ì¤‘ë¶€+ë™ì„œ_ë³€ìˆ˜ëˆ„ì ì¤‘ìš”ë„.png")
elimination_csv = os.path.join(save_dir, "ì¤‘ë¶€+ë™ì„œ_ë³€ìˆ˜ì œê±°_ê²°ê³¼.csv")
r2_plot = os.path.join(save_dir, "ì¤‘ë¶€+ë™ì„œ_R2ë³€í™”.png")
rmse_plot = os.path.join(save_dir, "ì¤‘ë¶€+ë™ì„œ_RMSEë³€í™”.png")

# ======================================================
# ğŸ”¹ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# ======================================================
df = pd.read_csv(file_path, encoding='utf-8-sig')
df['ì¼ê°•ìˆ˜ëŸ‰(mm)'] = df['ì¼ê°•ìˆ˜ëŸ‰(mm)'].fillna(0)
df = df.dropna(subset=['í•©ê³„ ì¼ì‚¬ëŸ‰(MJ/m2)'])

X = df[['ì„¤ë¹„ìš©ëŸ‰(MW)', 'í‰ê· ê¸°ì˜¨(Â°C)', 'ì¼ê°•ìˆ˜ëŸ‰(mm)',
        'í‰ê·  í’ì†(m/s)', 'í‰ê·  ìƒëŒ€ìŠµë„(%)',
        'í•©ê³„ ì¼ì¡°ì‹œê°„(hr)', 'í•©ê³„ ì¼ì‚¬ëŸ‰(MJ/m2)']]
y = df['ë°œì „ëŸ‰(MWh)']

# í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ======================================================
# 1ï¸âƒ£ ê¸°ë³¸ ëª¨ë¸ í•™ìŠµ
# ======================================================
model = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=-1)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

r2 = r2_score(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred) ** 0.5

print(f"âœ… í†µí•© ëª¨ë¸ RÂ²: {r2:.4f}")
print(f"âœ… í†µí•© ëª¨ë¸ RMSE: {rmse:.4f}")

results_df = pd.DataFrame({
    "ëª¨ë¸": ["í†µí•© RandomForest"],
    "ê²°ì •ê³„ìˆ˜(RÂ²)": [round(r2, 4)],
    "RMSE": [round(rmse, 4)],
    "ë°ì´í„° ìˆ˜": [len(X)]
})
results_df.to_csv(output_csv, index=False, encoding='utf-8-sig')

# ======================================================
# 2ï¸âƒ£ ë³€ìˆ˜ ì¤‘ìš”ë„ ë° ëˆ„ì  ì¤‘ìš”ë„
# ======================================================
importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)

importance_df = pd.DataFrame({
    "ë³€ìˆ˜ëª…": importances.index,
    "ì¤‘ìš”ë„": importances.values
})
importance_df.to_csv(importance_csv, index=False, encoding='utf-8-sig')

# ğŸ”¹ ì¤‘ìš”ë„ ë§‰ëŒ€ ê·¸ë˜í”„
plt.figure(figsize=(8, 5))
bars = plt.barh(importance_df['ë³€ìˆ˜ëª…'][::-1], importance_df['ì¤‘ìš”ë„'][::-1], color='skyblue')
plt.title("ë³€ìˆ˜ë³„ ì¤‘ìš”ë„ (í†µí•© RandomForest)")
plt.xlabel("ì¤‘ìš”ë„")
plt.grid(axis='x', linestyle='--', alpha=0.7)
for bar in bars:
    width = bar.get_width()
    plt.text(width + 0.002, bar.get_y() + bar.get_height()/2,
             f"{width:.3f}", va='center', fontsize=10)
plt.tight_layout()
plt.savefig(importance_img, dpi=300)
plt.close()

# ğŸ”¹ ëˆ„ì  ì¤‘ìš”ë„ ê³„ì‚°
importance_df['ëˆ„ì ì¤‘ìš”ë„(%)'] = importance_df['ì¤‘ìš”ë„'].cumsum() / importance_df['ì¤‘ìš”ë„'].sum() * 100

plt.figure(figsize=(8, 5))
plt.plot(range(1, len(importance_df) + 1),
         importance_df['ëˆ„ì ì¤‘ìš”ë„(%)'], marker='o', color='orange', linewidth=2)
plt.title("ë³€ìˆ˜ ëˆ„ì  ì¤‘ìš”ë„ (Top-N ê¸°ì¤€)")
plt.xlabel("ë³€ìˆ˜ ê°œìˆ˜ (ì¤‘ìš”ë„ ìˆœ)")
plt.ylabel("ëˆ„ì  ì¤‘ìš”ë„(%)")
plt.axhline(y=80, color='red', linestyle='--', linewidth=1)
plt.axhline(y=90, color='green', linestyle='--', linewidth=1)
plt.text(len(importance_df)*0.9, 80, "80%", color='red', va='bottom')
plt.text(len(importance_df)*0.9, 90, "90%", color='green', va='bottom')
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig(cumulative_img, dpi=300)
plt.close()

# ======================================================
# 3ï¸âƒ£ ë³€ìˆ˜ ì œê±° ì‹¤í—˜ (ì¤‘ìš”ë„ ë‚®ì€ ìˆœì„œë¶€í„° ì œê±°)
# ======================================================
sorted_features = list(importances.sort_values(ascending=True).index)  # ë‚®ì€ìˆœ ì •ë ¬
remaining_features = list(X.columns)

r2_scores = []
rmse_scores = []
feature_counts = []
used_features = []

for step in range(len(sorted_features)):
    # ëª¨ë¸ í•™ìŠµ
    X_train_sub = X_train[remaining_features]
    X_test_sub = X_test[remaining_features]

    model_sub = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=-1)
    model_sub.fit(X_train_sub, y_train)
    y_pred_sub = model_sub.predict(X_test_sub)

    r2_sub = r2_score(y_test, y_pred_sub)
    rmse_sub = mean_squared_error(y_test, y_pred_sub) ** 0.5

    r2_scores.append(r2_sub)
    rmse_scores.append(rmse_sub)
    feature_counts.append(len(remaining_features))
    used_features.append(", ".join(remaining_features))

    print(f"ğŸ”¹ ë³€ìˆ˜ {len(remaining_features)}ê°œ â†’ RÂ²={r2_sub:.4f}, RMSE={rmse_sub:.4f}")

    # ë‹¤ìŒ ë‹¨ê³„: ê°€ì¥ ì¤‘ìš”ë„ ë‚®ì€ ë³€ìˆ˜ ì œê±°
    if step < len(sorted_features) - 1:
        remove_var = sorted_features[step]
        remaining_features.remove(remove_var)

# ======================================================
# 4ï¸âƒ£ ê²°ê³¼ ì €ì¥ ë° ì‹œê°í™”
# ======================================================
elim_df = pd.DataFrame({
    "ë‚¨ì€ ë³€ìˆ˜ ìˆ˜": feature_counts,
    "ì‚¬ìš© ë³€ìˆ˜": used_features,
    "RÂ²": r2_scores,
    "RMSE": rmse_scores
})
elim_df.to_csv(elimination_csv, index=False, encoding='utf-8-sig')
print(f"\nğŸ“ ë³€ìˆ˜ ì œê±° ì‹¤í—˜ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {elimination_csv}")

# RÂ² ë³€í™” ê·¸ë˜í”„
plt.figure(figsize=(7, 5))
plt.plot(feature_counts, r2_scores, 'o-', color='blue', label='RÂ²')
plt.title("ë³€ìˆ˜ ì œê±°ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™” (RÂ²)")
plt.xlabel("ë‚¨ì€ ë³€ìˆ˜ ìˆ˜")
plt.ylabel("RÂ²")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.savefig(r2_plot, dpi=300)
plt.close()

# RMSE ë³€í™” ê·¸ë˜í”„
plt.figure(figsize=(7, 5))
plt.plot(feature_counts, rmse_scores, 'o-', color='red', label='RMSE')
plt.title("ë³€ìˆ˜ ì œê±°ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™” (RMSE)")
plt.xlabel("ë‚¨ì€ ë³€ìˆ˜ ìˆ˜")
plt.ylabel("RMSE")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.savefig(rmse_plot, dpi=300)
plt.close()

print(f"ğŸ–¼ï¸ ì„±ëŠ¥ ë³€í™” ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {r2_plot}, {rmse_plot}")

# ======================================================
# 5ï¸âƒ£ ì‹¤ì œ vs ì˜ˆì¸¡ ì‚°ì ë„
# ======================================================
plt.figure(figsize=(6, 6))
plt.scatter(y_test, y_pred, alpha=0.5, color='royalblue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],
         'r--', lw=2, label="ì™„ë²½ ì˜ˆì¸¡ì„  (y=x)")
plt.title("í…ŒìŠ¤íŠ¸ ë°ì´í„°: ì‹¤ì œ ë°œì „ëŸ‰ vs ì˜ˆì¸¡ ë°œì „ëŸ‰")
plt.xlabel("ì‹¤ì œ ë°œì „ëŸ‰(MWh)")
plt.ylabel("ì˜ˆì¸¡ ë°œì „ëŸ‰(MWh)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
